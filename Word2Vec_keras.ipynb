{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishalghosalkar001/testRepo001/blob/master/Word2Vec_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "adv5p_-Kx28k"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "pd.options.display.max_colwidth = 200\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "OT8sS8FcxeUY",
        "outputId": "ab024c33-5527-4204-ee7a-f88d1f72c3f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                             Document Category\n",
              "0                                      The sky is blue and beautiful.  weather\n",
              "1                                   Love this blue and beautiful sky!  weather\n",
              "2                        The quick brown fox jumps over the lazy dog.  animals\n",
              "3  A king's breakfast has sausages, ham, bacon, eggs, toast and beans     food\n",
              "4                         I love green eggs, ham, sausages and bacon!     food\n",
              "5                    The brown fox is quick and the blue dog is lazy!  animals\n",
              "6            The sky is very blue and the sky is very beautiful today  weather\n",
              "7                         The dog is lazy but the brown fox is quick!  animals"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f0bf70f9-7dbd-4f75-aa11-845b2a449e31\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Document</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The sky is blue and beautiful.</td>\n",
              "      <td>weather</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Love this blue and beautiful sky!</td>\n",
              "      <td>weather</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The quick brown fox jumps over the lazy dog.</td>\n",
              "      <td>animals</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A king's breakfast has sausages, ham, bacon, eggs, toast and beans</td>\n",
              "      <td>food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I love green eggs, ham, sausages and bacon!</td>\n",
              "      <td>food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>The brown fox is quick and the blue dog is lazy!</td>\n",
              "      <td>animals</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>The sky is very blue and the sky is very beautiful today</td>\n",
              "      <td>weather</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>The dog is lazy but the brown fox is quick!</td>\n",
              "      <td>animals</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f0bf70f9-7dbd-4f75-aa11-845b2a449e31')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f0bf70f9-7dbd-4f75-aa11-845b2a449e31 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f0bf70f9-7dbd-4f75-aa11-845b2a449e31');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "corpus = ['The sky is blue and beautiful.',\n",
        "          'Love this blue and beautiful sky!',\n",
        "          'The quick brown fox jumps over the lazy dog.',\n",
        "          \"A king's breakfast has sausages, ham, bacon, eggs, toast and beans\",\n",
        "          'I love green eggs, ham, sausages and bacon!',\n",
        "          'The brown fox is quick and the blue dog is lazy!',\n",
        "          'The sky is very blue and the sky is very beautiful today',\n",
        "          'The dog is lazy but the brown fox is quick!'    \n",
        "]\n",
        "labels = ['weather', 'weather', 'animals', 'food', 'food', 'animals', 'weather', 'animals']\n",
        "\n",
        "corpus = np.array(corpus)\n",
        "corpus_df = pd.DataFrame({'Document': corpus, \n",
        "                          'Category': labels})\n",
        "corpus_df = corpus_df[['Document', 'Category']]\n",
        "corpus_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lknXTS28xklk",
        "outputId": "1f635ac1-9472-4001-c041-0e7a8a5c79f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "wpt = nltk.WordPunctTokenizer()\n",
        "stop_words = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "def normalize_document(doc):\n",
        "    # lower case and remove special characters\\whitespaces\n",
        "    doc = re.sub(r'[^a-zA-Z\\s]', '', doc, re.I|re.A)\n",
        "    doc = doc.lower()\n",
        "    doc = doc.strip()\n",
        "    # tokenize document\n",
        "    tokens = wpt.tokenize(doc)\n",
        "    # filter stopwords out of document\n",
        "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
        "    # re-create document from filtered tokens\n",
        "    doc = ' '.join(filtered_tokens)\n",
        "    return doc\n",
        "\n",
        "normalize_corpus = np.vectorize(normalize_document)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2JmoapwyMto",
        "outputId": "3811d6b3-6971-4b07-c70f-ccca6bac47d0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['sky blue beautiful', 'love blue beautiful sky',\n",
              "       'quick brown fox jumps lazy dog',\n",
              "       'kings breakfast sausages ham bacon eggs toast beans',\n",
              "       'love green eggs ham sausages bacon',\n",
              "       'brown fox quick blue dog lazy', 'sky blue sky beautiful today',\n",
              "       'dog lazy brown fox quick'], dtype='<U51')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "norm_corpus = normalize_corpus(corpus)\n",
        "norm_corpus"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "2RRyGQZ4_EFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ohjqtzwzyyw7"
      },
      "source": [
        "##The Word2Vec Model\n",
        "This model was created by Google in 2013 and is a predictive deep learning based model to compute and generate high quality, distributed and continuous dense vector representations of words, which capture contextual and semantic similarity. Essentially these are unsupervised models which can take in massive textual corpora, create a vocabulary of possible words and generate dense word embeddings for each word in the vector space representing that vocabulary. Usually you can specify the size of the word embedding vectors and the total number of vectors are essentially the size of the vocabulary. This makes the dimensionality of this dense vector space much lower than the high-dimensional sparse vector space built using traditional Bag of Words models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Eo5hOMVy6b-"
      },
      "source": [
        "####The Continuous Bag of Words (CBOW) Model\n",
        "The CBOW model architecture tries to predict the current target word (the center word) based on the source context words (surrounding words). Considering a simple sentence, “the quick brown fox jumps over the lazy dog”, this can be pairs of (context_window, target_word) where if we consider a context window of size 2, we have examples like ([quick, fox], brown), ([the, brown], quick), ([the, dog], lazy) and so on. Thus the model tries to predict the target_word based on the context_window words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ncgy7oOzzE83"
      },
      "source": [
        "####Build the corpus vocabulary\n",
        "To start off, we will first build our corpus vocabulary where we extract out each unique word from our vocabulary and map a unique numeric identifier to it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_myObhd0ysSN",
        "outputId": "862db803-e408-4536-e2a0-cc63e76e3f39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary Size: 21\n",
            "Vocabulary Sample: [('sky', 1), ('blue', 2), ('beautiful', 3), ('quick', 4), ('brown', 5), ('fox', 6), ('lazy', 7), ('dog', 8), ('love', 9), ('sausages', 10)]\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing import text\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "tokenizer = text.Tokenizer()\n",
        "tokenizer.fit_on_texts(norm_corpus)\n",
        "word2id = tokenizer.word_index\n",
        "\n",
        "# build vocabulary of unique words\n",
        "word2id['PAD'] = 0\n",
        "id2word = {v:k for k, v in word2id.items()}\n",
        "wids = [[word2id[w] for w in text.text_to_word_sequence(doc)] for doc in norm_corpus]\n",
        "\n",
        "vocab_size = len(word2id)\n",
        "embed_size = 30\n",
        "window_size = 2 # context window size\n",
        "\n",
        "print('Vocabulary Size:', vocab_size)\n",
        "print('Vocabulary Sample:', list(word2id.items())[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwEmspbMzNSH"
      },
      "source": [
        "####Build a CBOW (context, target) generator\n",
        "We need pairs which consist of a target centre word and surround context words. In our implementation, a target word is of length 1 and surrounding context is of length 2 x window_size where we take window_size words before and after the target word in our corpus. This will become clearer with the following example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64xF05eDzOlW",
        "outputId": "cc689854-48ce-42d8-b896-4f2a2b42498b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context (X): ['quick', 'brown', 'jumps', 'lazy'] -> Target (Y): fox\n",
            "Context (X): ['brown', 'fox', 'lazy', 'dog'] -> Target (Y): jumps\n",
            "Context (X): ['kings', 'breakfast', 'ham', 'bacon'] -> Target (Y): sausages\n",
            "Context (X): ['breakfast', 'sausages', 'bacon', 'eggs'] -> Target (Y): ham\n",
            "Context (X): ['sausages', 'ham', 'eggs', 'toast'] -> Target (Y): bacon\n",
            "Context (X): ['ham', 'bacon', 'toast', 'beans'] -> Target (Y): eggs\n",
            "Context (X): ['love', 'green', 'ham', 'sausages'] -> Target (Y): eggs\n",
            "Context (X): ['green', 'eggs', 'sausages', 'bacon'] -> Target (Y): ham\n",
            "Context (X): ['brown', 'fox', 'blue', 'dog'] -> Target (Y): quick\n",
            "Context (X): ['fox', 'quick', 'dog', 'lazy'] -> Target (Y): blue\n",
            "Context (X): ['sky', 'blue', 'beautiful', 'today'] -> Target (Y): sky\n"
          ]
        }
      ],
      "source": [
        "def generate_context_word_pairs(corpus, window_size, vocab_size):\n",
        "    context_length = window_size*2\n",
        "    for words in corpus:\n",
        "        sentence_length = len(words)\n",
        "        for index, word in enumerate(words):\n",
        "            context_words = []\n",
        "            label_word   = []            \n",
        "            start = index - window_size\n",
        "            end = index + window_size + 1\n",
        "            \n",
        "            context_words.append([words[i] \n",
        "                                 for i in range(start, end) \n",
        "                                 if 0 <= i < sentence_length \n",
        "                                 and i != index])\n",
        "            label_word.append(word)\n",
        "\n",
        "            x = sequence.pad_sequences(context_words, maxlen=context_length)\n",
        "            y = np_utils.to_categorical(label_word, vocab_size)\n",
        "            yield (x, y)\n",
        "            \n",
        "            \n",
        "# Test this out for some samples\n",
        "i = 0\n",
        "for x, y in generate_context_word_pairs(corpus=wids, window_size=window_size, vocab_size=vocab_size):\n",
        "    if 0 not in x[0]:\n",
        "        print('Context (X):', [id2word[w] for w in x[0]], '-> Target (Y):', id2word[np.argwhere(y[0])[0][0]])\n",
        "    \n",
        "        if i == 10:\n",
        "            break\n",
        "        i += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TT_SVpdwzRiz"
      },
      "source": [
        "####Build the CBOW model architecture\n",
        "We now leverage keras on top of tensorflow to build our deep learning architecture for the CBOW model. For this our inputs will be our context words which are passed to an embedding layer (initialized with random weights). The word embeddings are propagated to a lambda layer where we average out the word embeddings (hence called CBOW because we don’t really consider the order or sequence in the context words when averaged) and then we pass this averaged context embedding to a dense softmax layer which predicts our target word. We match this with the actual target word, compute the loss by leveraging the categorical_crossentropy loss and perform backpropagation with each epoch to update the embedding layer in the process. Following code shows us our model architecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMWeOQhQzXeb"
      },
      "outputs": [],
      "source": [
        "import keras.backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, Lambda\n",
        "\n",
        "# build CBOW architecture\n",
        "cbow = Sequential()\n",
        "cbow.add(Embedding(input_dim=vocab_size, output_dim=embed_size, input_length=window_size*2))\n",
        "cbow.add(Lambda(lambda x: K.mean(x, axis=1), output_shape=(embed_size,)))\n",
        "cbow.add(Dense(vocab_size, activation='softmax'))\n",
        "cbow.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "# view model summary\n",
        "print(cbow.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0XCGzfSzncR"
      },
      "source": [
        "To summarize the core concepts of this model in simple terms, we have input context words of dimensions (2 x window_size), we will pass them to an embedding layer of size (vocab_size x embed_size) which will give us dense word embeddings for each of these context words (1 x embed_size for each word). Next up we use a lambda layer to average out these embeddings and get an average dense embedding (1 x embed_size) which is sent to the dense softmax layer which outputs the most likely target word. We compare this with the actual target word, compute the loss, backpropagate the errors to adjust the weights (in the embedding layer) and repeat this process for all (context, target) pairs for multiple epochs. The following figure tries to explain the same."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bHoTUeJz39J"
      },
      "source": [
        "####Train the Model\n",
        "Running the model on our complete corpus takes a fair bit of time, so I just ran it for 5 epochs. You can leverage the following code and increase it for more epochs if necessary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qh9Dp3ESz3Ix"
      },
      "outputs": [],
      "source": [
        "for epoch in range(1, 100):\n",
        "    loss = 0.\n",
        "    i = 0\n",
        "    for x, y in generate_context_word_pairs(corpus=wids, window_size=window_size, vocab_size=vocab_size):\n",
        "        i += 1\n",
        "        loss += cbow.train_on_batch(x, y)\n",
        "        if i % 100000 == 0:\n",
        "            print('Processed {} (context, word) pairs'.format(i))\n",
        "\n",
        "    print('Epoch:', epoch, '\\tLoss:', loss)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RusFJN-fz-Aq"
      },
      "source": [
        "####Get Word Embeddings\n",
        "To get word embeddings for our entire vocabulary, we can extract out the same from our embedding layer by leveraging the following code. We don’t take the embedding at position 0 since it belongs to the padding (PAD) term which is not really a word of interest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I73rCWqJ0A-8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "3295ae23-5649-4898-ebee-e2bb1dc05f48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20, 30)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 0         1         2         3         4         5   \\\n",
              "blue      -1.056325  0.073911  0.398076  1.045604  0.087906 -0.647943   \n",
              "beautiful -0.009490  0.661241 -0.474563  0.409241  1.350211  0.154913   \n",
              "quick     -1.001877 -0.383566  1.523314  0.107873 -0.662151  0.005115   \n",
              "brown      0.486977 -1.368317 -0.684468 -0.146448  0.835967 -1.198132   \n",
              "fox        1.226469 -0.987464 -0.933312  0.051496  0.987510  0.292376   \n",
              "\n",
              "                 6         7         8         9   ...        20        21  \\\n",
              "blue      -0.755652  0.314727  0.366467 -0.394197  ...  0.734630 -0.311624   \n",
              "beautiful -0.607648  0.066068  0.908472 -0.964226  ...  0.568870 -0.918025   \n",
              "quick     -0.333009  1.096868 -0.029924 -0.412661  ...  0.226992 -0.615409   \n",
              "brown     -1.412988 -0.080053 -1.237034 -0.042402  ...  0.603156  0.068608   \n",
              "fox       -0.923795  0.959272 -0.025270  0.166759  ... -0.321244 -0.330172   \n",
              "\n",
              "                 22        23        24        25        26        27  \\\n",
              "blue      -1.041767 -0.807258 -0.056280  0.727573 -0.080360  0.097368   \n",
              "beautiful -1.000859 -0.795024 -0.595539 -1.008232 -0.485314 -0.312635   \n",
              "quick     -0.872711 -0.526169 -0.287452  0.439517 -0.187920 -0.420505   \n",
              "brown      0.642520  0.408170 -1.343790  1.039482  0.881929  0.767231   \n",
              "fox        0.625232 -0.545134 -1.019887 -0.957494  0.492093  0.963302   \n",
              "\n",
              "                 28        29  \n",
              "blue      -0.608945 -1.049852  \n",
              "beautiful -0.006286  0.127771  \n",
              "quick     -0.150454 -0.664110  \n",
              "brown     -1.247231  0.808812  \n",
              "fox        0.252083  1.223700  \n",
              "\n",
              "[5 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0e25d235-448c-47e5-97ef-09bea495c9de\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>blue</th>\n",
              "      <td>-1.056325</td>\n",
              "      <td>0.073911</td>\n",
              "      <td>0.398076</td>\n",
              "      <td>1.045604</td>\n",
              "      <td>0.087906</td>\n",
              "      <td>-0.647943</td>\n",
              "      <td>-0.755652</td>\n",
              "      <td>0.314727</td>\n",
              "      <td>0.366467</td>\n",
              "      <td>-0.394197</td>\n",
              "      <td>...</td>\n",
              "      <td>0.734630</td>\n",
              "      <td>-0.311624</td>\n",
              "      <td>-1.041767</td>\n",
              "      <td>-0.807258</td>\n",
              "      <td>-0.056280</td>\n",
              "      <td>0.727573</td>\n",
              "      <td>-0.080360</td>\n",
              "      <td>0.097368</td>\n",
              "      <td>-0.608945</td>\n",
              "      <td>-1.049852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>beautiful</th>\n",
              "      <td>-0.009490</td>\n",
              "      <td>0.661241</td>\n",
              "      <td>-0.474563</td>\n",
              "      <td>0.409241</td>\n",
              "      <td>1.350211</td>\n",
              "      <td>0.154913</td>\n",
              "      <td>-0.607648</td>\n",
              "      <td>0.066068</td>\n",
              "      <td>0.908472</td>\n",
              "      <td>-0.964226</td>\n",
              "      <td>...</td>\n",
              "      <td>0.568870</td>\n",
              "      <td>-0.918025</td>\n",
              "      <td>-1.000859</td>\n",
              "      <td>-0.795024</td>\n",
              "      <td>-0.595539</td>\n",
              "      <td>-1.008232</td>\n",
              "      <td>-0.485314</td>\n",
              "      <td>-0.312635</td>\n",
              "      <td>-0.006286</td>\n",
              "      <td>0.127771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>quick</th>\n",
              "      <td>-1.001877</td>\n",
              "      <td>-0.383566</td>\n",
              "      <td>1.523314</td>\n",
              "      <td>0.107873</td>\n",
              "      <td>-0.662151</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>-0.333009</td>\n",
              "      <td>1.096868</td>\n",
              "      <td>-0.029924</td>\n",
              "      <td>-0.412661</td>\n",
              "      <td>...</td>\n",
              "      <td>0.226992</td>\n",
              "      <td>-0.615409</td>\n",
              "      <td>-0.872711</td>\n",
              "      <td>-0.526169</td>\n",
              "      <td>-0.287452</td>\n",
              "      <td>0.439517</td>\n",
              "      <td>-0.187920</td>\n",
              "      <td>-0.420505</td>\n",
              "      <td>-0.150454</td>\n",
              "      <td>-0.664110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>brown</th>\n",
              "      <td>0.486977</td>\n",
              "      <td>-1.368317</td>\n",
              "      <td>-0.684468</td>\n",
              "      <td>-0.146448</td>\n",
              "      <td>0.835967</td>\n",
              "      <td>-1.198132</td>\n",
              "      <td>-1.412988</td>\n",
              "      <td>-0.080053</td>\n",
              "      <td>-1.237034</td>\n",
              "      <td>-0.042402</td>\n",
              "      <td>...</td>\n",
              "      <td>0.603156</td>\n",
              "      <td>0.068608</td>\n",
              "      <td>0.642520</td>\n",
              "      <td>0.408170</td>\n",
              "      <td>-1.343790</td>\n",
              "      <td>1.039482</td>\n",
              "      <td>0.881929</td>\n",
              "      <td>0.767231</td>\n",
              "      <td>-1.247231</td>\n",
              "      <td>0.808812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fox</th>\n",
              "      <td>1.226469</td>\n",
              "      <td>-0.987464</td>\n",
              "      <td>-0.933312</td>\n",
              "      <td>0.051496</td>\n",
              "      <td>0.987510</td>\n",
              "      <td>0.292376</td>\n",
              "      <td>-0.923795</td>\n",
              "      <td>0.959272</td>\n",
              "      <td>-0.025270</td>\n",
              "      <td>0.166759</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.321244</td>\n",
              "      <td>-0.330172</td>\n",
              "      <td>0.625232</td>\n",
              "      <td>-0.545134</td>\n",
              "      <td>-1.019887</td>\n",
              "      <td>-0.957494</td>\n",
              "      <td>0.492093</td>\n",
              "      <td>0.963302</td>\n",
              "      <td>0.252083</td>\n",
              "      <td>1.223700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0e25d235-448c-47e5-97ef-09bea495c9de')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0e25d235-448c-47e5-97ef-09bea495c9de button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0e25d235-448c-47e5-97ef-09bea495c9de');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "weights = cbow.get_weights()[0]\n",
        "weights = weights[1:]\n",
        "print(weights.shape)\n",
        "\n",
        "pd.DataFrame(weights, index=list(id2word.values())[1:]).head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRpnRW0g0Gks"
      },
      "source": [
        "Thus you can clearly see that each word has a dense embedding of size (1x30) as depicted in the preceding output. Let’s try and find out some contextually similar words for specific words of interest based on these embeddings. For this, we build out a pairwise distance matrix amongst all the words in our vocabulary based on the dense embedding vectors and then find out the n-nearest neighbors of each word of interest based on the shortest (euclidean) distance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n72EWJ_I0D30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39d045fa-e0f8-4bae-9dc4-cec51b859022"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20, 20)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'beautiful': ['sky', 'love'],\n",
              " 'blue': ['today', 'sky'],\n",
              " 'brown': ['jumps', 'fox'],\n",
              " 'fox': ['dog', 'jumps'],\n",
              " 'quick': ['jumps', 'lazy']}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "\n",
        "# compute pairwise distance matrix\n",
        "distance_matrix = euclidean_distances(weights)\n",
        "print(distance_matrix.shape)\n",
        "\n",
        "# view contextually similar words\n",
        "similar_words = {search_term: [id2word[idx] for idx in distance_matrix[word2id[search_term]-1].argsort()[1:3]+1] \n",
        "                   for search_term in ['blue', 'beautiful', 'quick', 'brown', 'fox']}\n",
        "\n",
        "similar_words"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Word2Vec_keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}